{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cH8ZE_BW7xqc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import datasets, layers, models, losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7HDRM0k71r8",
        "outputId": "fc599f60-aa48-4b65-ebbe-fc3a9deac850"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "(x_train,y_train),(x_test,y_test) = datasets.cifar10.load_data()\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape converting 2D to 1D\n",
        "y_test = y_test.reshape(-1,)\n",
        "y_train = y_train.reshape(-1,)"
      ],
      "metadata": {
        "id": "8jwvCQmQ4u-_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code normalazation\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "metadata": {
        "id": "HI29iOwz4wr4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "LpUuFLJx4ztd",
        "outputId": "63765749-e1fe-4d54-b9ed-7e8b284b3c37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(6, 5, activation='relu', input_shape=(32,32,3),padding='same'))\n",
        "model.add(layers.AveragePooling2D(2))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Conv2D(16, 5, activation='tanh',padding='valid'))\n",
        "model.add(layers.AveragePooling2D(2))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Conv2D(120, 5, activation='tanh',padding='valid'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(84, activation='tanh'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "yDYB2LcR8PkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79eb51f8-5384-4df4-8514-4a0ea0b19f65"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 6)         456       \n",
            "                                                                 \n",
            " average_pooling2d_2 (Averag  (None, 16, 16, 6)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 6)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 12, 12, 16)        2416      \n",
            "                                                                 \n",
            " average_pooling2d_3 (Averag  (None, 6, 6, 16)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 6, 6, 16)          0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 2, 2, 120)         48120     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 480)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 84)                40404     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,246\n",
            "Trainable params: 92,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64\n",
        "epochs=10"
      ],
      "metadata": {
        "id": "K1U6wqHRjU9t"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base model accuracy\n",
        "model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
        "history_base = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test),verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT3ojZMg8PmM",
        "outputId": "71fa639f-b179-4013-db00-b9dd0d217679"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 66s 75ms/step - loss: 1.5996 - accuracy: 0.4157 - val_loss: 1.4442 - val_accuracy: 0.4790\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 60s 77ms/step - loss: 1.3802 - accuracy: 0.5033 - val_loss: 1.3830 - val_accuracy: 0.5044\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 57s 72ms/step - loss: 1.2968 - accuracy: 0.5353 - val_loss: 1.2606 - val_accuracy: 0.5486\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 56s 71ms/step - loss: 1.2397 - accuracy: 0.5586 - val_loss: 1.2277 - val_accuracy: 0.5607\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 1.1934 - accuracy: 0.5732 - val_loss: 1.2002 - val_accuracy: 0.5648\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 1.1492 - accuracy: 0.5921 - val_loss: 1.1846 - val_accuracy: 0.5749\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 57s 73ms/step - loss: 1.1162 - accuracy: 0.6045 - val_loss: 1.1487 - val_accuracy: 0.5923\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 1.0844 - accuracy: 0.6184 - val_loss: 1.1698 - val_accuracy: 0.5820\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 1.0543 - accuracy: 0.6284 - val_loss: 1.1728 - val_accuracy: 0.5874\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 1.0305 - accuracy: 0.6379 - val_loss: 1.1247 - val_accuracy: 0.5994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test baseline accuracy\n",
        "import tempfile\n",
        "\n",
        "_, baseline_model_accuracy = model.evaluate(x_test,y_test, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n"
      ],
      "metadata": {
        "id": "zsce210CHduF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd6b208-2095-4561-f23f-e52d85912d02"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.599399983882904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base model saved location\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving model to: ', keras_file)\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2lQ8w0xW-vw",
        "outputId": "ac9edeb4-bdff-4504-a3f9-37ff62ea083c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to:  /tmp/tmpuxky2pj5.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################\n",
        "########### PRUNING ###########\n",
        "###############################"
      ],
      "metadata": {
        "id": "KbFQNPXaHn0U"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4FQzpMcD2U8",
        "outputId": "b6b35e0b-a9b3-48c5-a138-b21c4a67fc7e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.21.6)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (0.1.7)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prunning the entire dataset\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import numpy as np\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# batch_size & epochs stay the same as the baseline model\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "# Define model for pruning.\n",
        "# For the pruning schedule, we start at the sparsity level 50% \n",
        "# and gradually train the model to reach 90% sparsity. \n",
        "# 90% of the weight tensor is going to be pruned away.\n",
        "\n",
        "x = 0.2\n",
        "sparsity = []\n",
        "acc = []\n",
        "while x <= 0.9:\n",
        "  print(\"current x is: \",x)\n",
        "  sparsity.append(x)\n",
        "  pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(x, begin_step=0, frequency=100)\n",
        "  }\n",
        "  callbacks = [\n",
        "      tfmot.sparsity.keras.UpdatePruningStep()\n",
        "    ]\n",
        "\n",
        "  model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "  # `prune_low_magnitude` requires a recompile.\n",
        "  model_for_pruning.compile(optimizer='adam',\n",
        "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                            metrics=['accuracy'])\n",
        "\n",
        "  history_pruned = model_for_pruning.fit(x_train,y_train,\n",
        "                      batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test),\n",
        "                      callbacks=callbacks)\n",
        "    \n",
        "  _, model_for_pruning_accuracy = model_for_pruning.evaluate(x_train,y_train, verbose=0)\n",
        "\n",
        "  print(\"current x is: \",x, \"and model acc is: \",model_for_pruning_accuracy)\n",
        "  acc.append(model_for_pruning_accuracy)\n",
        "  print(\"sparsity: \", sparsity)\n",
        "  print(\"accuracy list: \", acc)\n",
        "  x += 0.1\n",
        "\n",
        "# model_for_pruning.summary()"
      ],
      "metadata": {
        "id": "5TjUZxOvZO0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c9312f-4929-4b00-c6a1-4894e39d124a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current x is:  0.2\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 65s 78ms/step - loss: 0.9846 - accuracy: 0.6549 - val_loss: 1.0687 - val_accuracy: 0.6222\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.9562 - accuracy: 0.6626 - val_loss: 1.0714 - val_accuracy: 0.6198\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 60s 77ms/step - loss: 0.9399 - accuracy: 0.6737 - val_loss: 1.1061 - val_accuracy: 0.6072\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 62s 79ms/step - loss: 0.9175 - accuracy: 0.6805 - val_loss: 1.0684 - val_accuracy: 0.6274\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 60s 76ms/step - loss: 0.9011 - accuracy: 0.6835 - val_loss: 1.0593 - val_accuracy: 0.6297\n",
            "current x is:  0.2 and model acc is:  0.7028999924659729\n",
            "sparsity:  [0.2]\n",
            "accuracy list:  [0.7028999924659729]\n",
            "current x is:  0.30000000000000004\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 64s 79ms/step - loss: 0.8752 - accuracy: 0.6903 - val_loss: 1.0382 - val_accuracy: 0.6354\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 62s 79ms/step - loss: 0.8515 - accuracy: 0.7013 - val_loss: 1.0575 - val_accuracy: 0.6318\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.8313 - accuracy: 0.7083 - val_loss: 1.0441 - val_accuracy: 0.6378\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 62s 80ms/step - loss: 0.8212 - accuracy: 0.7121 - val_loss: 1.0503 - val_accuracy: 0.6392\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.8036 - accuracy: 0.7192 - val_loss: 1.0774 - val_accuracy: 0.6306\n",
            "current x is:  0.30000000000000004 and model acc is:  0.7268999814987183\n",
            "sparsity:  [0.2, 0.30000000000000004]\n",
            "accuracy list:  [0.7028999924659729, 0.7268999814987183]\n",
            "current x is:  0.4\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 66s 81ms/step - loss: 0.7944 - accuracy: 0.7238 - val_loss: 1.0433 - val_accuracy: 0.6398\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 63s 80ms/step - loss: 0.7643 - accuracy: 0.7330 - val_loss: 1.0460 - val_accuracy: 0.6433\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 61s 78ms/step - loss: 0.7525 - accuracy: 0.7370 - val_loss: 1.0573 - val_accuracy: 0.6429\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 63s 80ms/step - loss: 0.7361 - accuracy: 0.7435 - val_loss: 1.0821 - val_accuracy: 0.6380\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 62s 79ms/step - loss: 0.7237 - accuracy: 0.7494 - val_loss: 1.0893 - val_accuracy: 0.6359\n",
            "current x is:  0.4 and model acc is:  0.7552800178527832\n",
            "sparsity:  [0.2, 0.30000000000000004, 0.4]\n",
            "accuracy list:  [0.7028999924659729, 0.7268999814987183, 0.7552800178527832]\n",
            "current x is:  0.5\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 64s 79ms/step - loss: 0.7445 - accuracy: 0.7378 - val_loss: 1.0551 - val_accuracy: 0.6432\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 64s 81ms/step - loss: 0.6973 - accuracy: 0.7551 - val_loss: 1.0721 - val_accuracy: 0.6427\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 61s 78ms/step - loss: 0.6841 - accuracy: 0.7611 - val_loss: 1.0725 - val_accuracy: 0.6464\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 63s 80ms/step - loss: 0.6658 - accuracy: 0.7688 - val_loss: 1.1121 - val_accuracy: 0.6372\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.6560 - accuracy: 0.7704 - val_loss: 1.1311 - val_accuracy: 0.6316\n",
            "current x is:  0.5 and model acc is:  0.7737799882888794\n",
            "sparsity:  [0.2, 0.30000000000000004, 0.4, 0.5]\n",
            "accuracy list:  [0.7028999924659729, 0.7268999814987183, 0.7552800178527832, 0.7737799882888794]\n",
            "current x is:  0.6\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 70s 86ms/step - loss: 0.7352 - accuracy: 0.7411 - val_loss: 1.0801 - val_accuracy: 0.6375\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 63s 80ms/step - loss: 0.6688 - accuracy: 0.7657 - val_loss: 1.1094 - val_accuracy: 0.6406\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 64s 81ms/step - loss: 0.6451 - accuracy: 0.7742 - val_loss: 1.1038 - val_accuracy: 0.6396\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 62s 80ms/step - loss: 0.6281 - accuracy: 0.7810 - val_loss: 1.1102 - val_accuracy: 0.6403\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 63s 81ms/step - loss: 0.6152 - accuracy: 0.7849 - val_loss: 1.1575 - val_accuracy: 0.6268\n",
            "current x is:  0.6 and model acc is:  0.7806400060653687\n",
            "sparsity:  [0.2, 0.30000000000000004, 0.4, 0.5, 0.6]\n",
            "accuracy list:  [0.7028999924659729, 0.7268999814987183, 0.7552800178527832, 0.7737799882888794, 0.7806400060653687]\n",
            "current x is:  0.7\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 62s 76ms/step - loss: 1.0288 - accuracy: 0.6415 - val_loss: 1.1325 - val_accuracy: 0.6176\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 62s 79ms/step - loss: 0.7373 - accuracy: 0.7378 - val_loss: 1.1070 - val_accuracy: 0.6360\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 61s 78ms/step - loss: 0.6971 - accuracy: 0.7528 - val_loss: 1.1047 - val_accuracy: 0.6302\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 62s 79ms/step - loss: 0.6729 - accuracy: 0.7641 - val_loss: 1.1094 - val_accuracy: 0.6401\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 61s 78ms/step - loss: 0.6572 - accuracy: 0.7675 - val_loss: 1.1274 - val_accuracy: 0.6356\n",
            "current x is:  0.7 and model acc is:  0.7821400165557861\n",
            "sparsity:  [0.2, 0.30000000000000004, 0.4, 0.5, 0.6, 0.7]\n",
            "accuracy list:  [0.7028999924659729, 0.7268999814987183, 0.7552800178527832, 0.7737799882888794, 0.7806400060653687, 0.7821400165557861]\n",
            "current x is:  0.7999999999999999\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 65s 80ms/step - loss: 1.1349 - accuracy: 0.6049 - val_loss: 1.1623 - val_accuracy: 0.5949\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.9122 - accuracy: 0.6764 - val_loss: 1.0786 - val_accuracy: 0.6305\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 61s 78ms/step - loss: 0.8577 - accuracy: 0.6993 - val_loss: 1.0697 - val_accuracy: 0.6358\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 63s 81ms/step - loss: 0.8283 - accuracy: 0.7085 - val_loss: 1.0691 - val_accuracy: 0.6338\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 63s 80ms/step - loss: 0.8065 - accuracy: 0.7179 - val_loss: 1.0525 - val_accuracy: 0.6429\n",
            "current x is:  0.7999999999999999 and model acc is:  0.7302799820899963\n",
            "sparsity:  [0.2, 0.30000000000000004, 0.4, 0.5, 0.6, 0.7, 0.7999999999999999]\n",
            "accuracy list:  [0.7028999924659729, 0.7268999814987183, 0.7552800178527832, 0.7737799882888794, 0.7806400060653687, 0.7821400165557861, 0.7302799820899963]\n",
            "current x is:  0.8999999999999999\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 71s 86ms/step - loss: 1.7449 - accuracy: 0.3586 - val_loss: 1.6190 - val_accuracy: 0.4096\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 63s 81ms/step - loss: 1.4184 - accuracy: 0.4878 - val_loss: 1.2910 - val_accuracy: 0.5414\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 63s 81ms/step - loss: 1.2097 - accuracy: 0.5726 - val_loss: 1.2034 - val_accuracy: 0.5775\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 63s 81ms/step - loss: 1.1373 - accuracy: 0.5988 - val_loss: 1.1889 - val_accuracy: 0.5834\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 63s 81ms/step - loss: 1.0954 - accuracy: 0.6141 - val_loss: 1.1362 - val_accuracy: 0.6021\n",
            "current x is:  0.8999999999999999 and model acc is:  0.6231799721717834\n",
            "sparsity:  [0.2, 0.30000000000000004, 0.4, 0.5, 0.6, 0.7, 0.7999999999999999, 0.8999999999999999]\n",
            "accuracy list:  [0.7028999924659729, 0.7268999814987183, 0.7552800178527832, 0.7737799882888794, 0.7806400060653687, 0.7821400165557861, 0.7302799820899963, 0.6231799721717834]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparsity = [round(x, 2) for x in sparsity]\n",
        "sparsity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO65-xSKut59",
        "outputId": "78004494-e297-4873-aa3b-7975a761d893"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RQ_VgnPuwv0",
        "outputId": "541b7e80-b0c9-4add-9608-8fc4b9344329"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7028999924659729,\n",
              " 0.7268999814987183,\n",
              " 0.7552800178527832,\n",
              " 0.7737799882888794,\n",
              " 0.7806400060653687,\n",
              " 0.7821400165557861,\n",
              " 0.7302799820899963,\n",
              " 0.6231799721717834]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # fit the pruned model\n",
        "\n",
        "# logdir = tempfile.mkdtemp()\n",
        "\n",
        "# callbacks = [\n",
        "#   tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "#   tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "# ]\n",
        "\n",
        "# history_pruned = model_for_pruning.fit(x_train,y_train,\n",
        "#                   batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
        "#                   callbacks=callbacks)"
      ],
      "metadata": {
        "id": "7d-X3PqEE_25"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out pruned model accuracy\n",
        "# _, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
        "#    x_train,y_train, verbose=0)"
      ],
      "metadata": {
        "id": "sTkfl80b2o-m"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare results\n",
        "print('Baseline test accuracy:', baseline_model_accuracy) \n",
        "print('Pruned test accuracy:', model_for_pruning_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy5TXkXi3GP4",
        "outputId": "baaecc5f-7611-49c0-b0ed-d1f1ec6640a1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.599399983882904\n",
            "Pruned test accuracy: 0.6231799721717834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Once our pre-trained model achieved desirable accuracy\n",
        "# we save the model trained model and make it “prunable”\n",
        "# _, keras_file = tempfile.mkstemp('.h5')\n",
        "# tf.keras.models.save_model(model_for_pruning, keras_file, include_optimizer=False)\n",
        "# print('Saved baseline model to:', keras_file)"
      ],
      "metadata": {
        "id": "6CCXJzyLSTvd"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compression_ratio = [1/x for x in sparsity]\n",
        "compression_ratio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILkolML0DH5Q",
        "outputId": "ab1e506b-efe1-4bc4-e6ea-732896634fa6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.0,\n",
              " 3.3333333333333335,\n",
              " 2.5,\n",
              " 2.0,\n",
              " 1.6666666666666667,\n",
              " 1.4285714285714286,\n",
              " 1.25,\n",
              " 1.1111111111111112]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfUOmFwRHqFg",
        "outputId": "1a21cde9-723e-4c9b-f647-c225ea4ede51"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7028999924659729,\n",
              " 0.7268999814987183,\n",
              " 0.7552800178527832,\n",
              " 0.7737799882888794,\n",
              " 0.7806400060653687,\n",
              " 0.7821400165557861,\n",
              " 0.7302799820899963,\n",
              " 0.6231799721717834]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pruned model saved\n",
        "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving model to: ', pruned_keras_file)\n",
        "tf.keras.models.save_model(model_for_pruning, pruned_keras_file, include_optimizer=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAPakfQNktBP",
        "outputId": "0a20ea29-4f88-4d32-d08d-06774db61636"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to:  /tmp/tmpvl_c46r1.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################\n",
        "###### PRUNING RESULT #########\n",
        "###############################"
      ],
      "metadata": {
        "id": "ouYSl9PxkTbn"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compression ratio vs accuracy graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "# plt.scatter(compression_rat, acc)\n",
        "ax.plot(compression_ratio, acc, linewidth=2.0)\n",
        "plt.xlabel('Compresion Ratio')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Compresion Ratio VS Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "l4WKeq4Z9jgn",
        "outputId": "3460eb76-572e-47e3-f20b-5a1cd9bf9a40"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy results\n",
        "print('Baseline test accuracy:', baseline_model_accuracy) \n",
        "print('Pruned test accuracy (90% pruned rate):', model_for_pruning_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaXou0THFM68",
        "outputId": "33fd057b-10eb-42c6-fd8e-2e427f1e2ee3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.599399983882904\n",
            "Pruned test accuracy (90% pruned rate): 0.6231799721717834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pruned model summary\n",
        "# model_for_pruning.summary()"
      ],
      "metadata": {
        "id": "1kkGkxKBIhxQ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base model summary\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "aBpM7UF9Kzog"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to get model size\n",
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "metadata": {
        "id": "H1Fm186si2le"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare model size\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSF_b1K2klTA",
        "outputId": "822c5e70-009a-478d-c811-bf9a1dff8076"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of gzipped baseline Keras model: 346362.00 bytes\n",
            "Size of gzipped pruned Keras model: 91857.00 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix for based model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "test_predictions = model.predict(x_test)\n",
        "confusion = confusion_matrix(y_test, np.argmax(test_predictions,axis=1))\n",
        "confusion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo8-Oz4ystSc",
        "outputId": "150aaba1-06e2-4e8e-ddfd-692c7715aee4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 6s 18ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[717,  25,  45,  11,  32,  10,   8,   3, 106,  43],\n",
              "       [ 33, 708,   8,   9,  14,   9,  17,   4,  53, 145],\n",
              "       [ 93,  11, 418,  56, 156, 142,  55,  32,  19,  18],\n",
              "       [ 51,  12,  64, 338,  99, 265,  65,  42,  29,  35],\n",
              "       [ 54,   4,  77,  61, 603,  52,  50,  69,  24,   6],\n",
              "       [ 23,   5,  53, 132,  81, 594,  23,  61,  16,  12],\n",
              "       [ 18,  17,  39,  61, 113,  61, 624,  17,  18,  32],\n",
              "       [ 29,   5,  45,  45,  98, 111,  15, 593,   9,  50],\n",
              "       [116,  56,  10,  13,   6,  13,   8,   8, 740,  30],\n",
              "       [ 41, 123,  12,  19,  11,  15,  15,  15,  63, 686]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix for pruned model\n",
        "p_test_predictions = model_for_pruning.predict(x_test)\n",
        "p_confusion = confusion_matrix(y_test, np.argmax(p_test_predictions,axis=1))\n",
        "p_confusion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeAi6GZ6pm6i",
        "outputId": "8160a89b-8165-475c-e9c2-9cd22bf1a9c9"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 6s 18ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[717,  25,  45,  11,  32,  10,   8,   3, 106,  43],\n",
              "       [ 33, 708,   8,   9,  14,   9,  17,   4,  53, 145],\n",
              "       [ 93,  11, 418,  56, 156, 142,  55,  32,  19,  18],\n",
              "       [ 51,  12,  64, 338,  99, 265,  65,  42,  29,  35],\n",
              "       [ 54,   4,  77,  61, 603,  52,  50,  69,  24,   6],\n",
              "       [ 23,   5,  53, 132,  81, 594,  23,  61,  16,  12],\n",
              "       [ 18,  17,  39,  61, 113,  61, 624,  17,  18,  32],\n",
              "       [ 29,   5,  45,  45,  98, 111,  15, 593,   9,  50],\n",
              "       [116,  56,  10,  13,   6,  13,   8,   8, 740,  30],\n",
              "       [ 41, 123,  12,  19,  11,  15,  15,  15,  63, 686]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################\n",
        "######## Quantization #########\n",
        "###############################"
      ],
      "metadata": {
        "id": "v5yiAke-NVhG"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Quantization \n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "model_quant = tfmot.quantization.keras.quantize_model(model)\n",
        "model_quant.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
        "model_quant.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quDmyFES3QkO",
        "outputId": "f4398736-674d-47d2-8e83-4a5a99fff999"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLay  (None, 32, 32, 3)        3         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " quant_conv2d_5 (QuantizeWra  (None, 32, 32, 6)        471       \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_average_pooling2d_2 (  (None, 16, 16, 6)        3         \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_activation_2 (Quantiz  (None, 16, 16, 6)        3         \n",
            " eWrapperV2)                                                     \n",
            "                                                                 \n",
            " quant_conv2d_6 (QuantizeWra  (None, 12, 12, 16)       2451      \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_average_pooling2d_3 (  (None, 6, 6, 16)         3         \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_activation_3 (Quantiz  (None, 6, 6, 16)         3         \n",
            " eWrapperV2)                                                     \n",
            "                                                                 \n",
            " quant_conv2d_7 (QuantizeWra  (None, 2, 2, 120)        48363     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_flatten_2 (QuantizeWr  (None, 480)              1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_dense_5 (QuantizeWrap  (None, 84)               40409     \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dense_6 (QuantizeWrap  (None, 10)               855       \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,565\n",
            "Trainable params: 92,246\n",
            "Non-trainable params: 319\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_quant.fit(x_train, y_train, batch_size=64, epochs=5, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qrVIH4-cts5",
        "outputId": "52371fae-d365-43d7-fe4a-6ace12d1999e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 76s 97ms/step - loss: 1.0935 - accuracy: 0.6127 - val_loss: 1.0451 - val_accuracy: 0.6326\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 71s 91ms/step - loss: 0.9672 - accuracy: 0.6597 - val_loss: 1.0834 - val_accuracy: 0.6205\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 69s 88ms/step - loss: 0.8988 - accuracy: 0.6875 - val_loss: 1.0781 - val_accuracy: 0.6323\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 77s 98ms/step - loss: 0.8610 - accuracy: 0.6995 - val_loss: 0.9800 - val_accuracy: 0.6645\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 69s 88ms/step - loss: 0.8201 - accuracy: 0.7126 - val_loss: 1.0231 - val_accuracy: 0.6486\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f71a09aa5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quant model saved\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_quant)\n",
        "quant_tflite_model = converter.convert()\n",
        "\n",
        "_, quant_tflite_file = tempfile.mkstemp('.h5')\n",
        "\n",
        "with open(quant_tflite_file, 'wb') as f:\n",
        "  f.write(quant_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', quant_tflite_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MnrqkLuEAyM",
        "outputId": "8772589b-a86f-47cf-b3bf-567d056f1fcd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_5_layer_call_fn, conv2d_5_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, activation_2_layer_call_fn, activation_2_layer_call_and_return_conditional_losses while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved pruned TFLite model to: /tmp/tmp3wvwxkwp.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################\n",
        "######## Quantization Result#########\n",
        "#####################################"
      ],
      "metadata": {
        "id": "Di97YRZXD7ki"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy comparisons\n",
        "_, model_quant_accuracy = model_quant.evaluate(x_train,y_train, verbose=0)\n",
        "print('Baseline test accuracy:', baseline_model_accuracy) \n",
        "print('Quantization test accuracy:', model_quant_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mswjUhcs41Vr",
        "outputId": "e90fa289-84d0-4a47-d613-663664e14605"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.599399983882904\n",
            "Quantization test accuracy: 0.7170000076293945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare model size\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped quantization Keras model: %.2f bytes\" % (get_gzipped_model_size(quant_tflite_file)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMYVTyOYEA1w",
        "outputId": "306378b3-b415-4f90-8b7e-85d913bdfcb4"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of gzipped baseline Keras model: 346362.00 bytes\n",
            "Size of gzipped quantization Keras model: 298284.00 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################\n",
        "######## Pruning + Quantization #########\n",
        "#########################################"
      ],
      "metadata": {
        "id": "W49wlVCs7XpU"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prunning the entire dataset\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import numpy as np\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# batch_size & epochs stay the same as the baseline model\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "# Define model for pruning.\n",
        "# For the pruning schedule, we start at the sparsity level 50% \n",
        "# and gradually train the model to reach 90% sparsity. \n",
        "# 90% of the weight tensor is going to be pruned away.\n",
        "\n",
        "x = 0.2\n",
        "sparsity_pq = []\n",
        "acc_pq = []\n",
        "while x <= 0.9:\n",
        "  print(\"current x is: \",x)\n",
        "  sparsity_pq.append(x)\n",
        "  pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(x, begin_step=0, frequency=100)\n",
        "  }\n",
        "  callbacks = [\n",
        "      tfmot.sparsity.keras.UpdatePruningStep()\n",
        "    ]\n",
        "\n",
        "  model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "  # `prune_low_magnitude` requires a recompile.\n",
        "  model_for_pruning.compile(optimizer='adam',\n",
        "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                            metrics=['accuracy'])\n",
        "\n",
        "  history_pruned = model_for_pruning.fit(x_train,y_train,\n",
        "                      batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val),\n",
        "                      callbacks=callbacks)\n",
        "\n",
        "                      \n",
        "  model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "  model_quant_prune = tfmot.quantization.keras.quantize_model(model_for_export)\n",
        "  model_quant_prune.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
        "  model_quant_prune.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val))\n",
        "    \n",
        "  _, model_quant_prune_accuracy = model_quant_prune.evaluate(x_train,y_train, verbose=0)\n",
        "\n",
        "  print(\"current x is: \",x, \"and model acc is: \",model_quant_prune_accuracy)\n",
        "  acc_pq.append(model_quant_prune_accuracy)\n",
        "  print(\"sparsity: \", sparsity_pq)\n",
        "  print(\"accuracy list: \", acc_pq)\n",
        "  x += 0.1\n",
        "\n",
        "# model_for_pruning.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWv7GXZ7RLAV",
        "outputId": "902f282d-2113-490e-ee91-9ecba78c53b9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current x is:  0.2\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 59s 73ms/step - loss: 1.0651 - accuracy: 0.6261 - val_loss: 0.9417 - val_accuracy: 0.6740\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.9451 - accuracy: 0.6667 - val_loss: 0.8515 - val_accuracy: 0.6920\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 0.8831 - accuracy: 0.6909 - val_loss: 0.7934 - val_accuracy: 0.7245\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.8383 - accuracy: 0.7058 - val_loss: 0.7852 - val_accuracy: 0.7285\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.8014 - accuracy: 0.7212 - val_loss: 0.7428 - val_accuracy: 0.7405\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 63s 79ms/step - loss: 0.8347 - accuracy: 0.7078 - val_loss: 0.7538 - val_accuracy: 0.7220\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 61s 78ms/step - loss: 0.7893 - accuracy: 0.7224 - val_loss: 0.7318 - val_accuracy: 0.7360\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 61s 78ms/step - loss: 0.7656 - accuracy: 0.7301 - val_loss: 0.6667 - val_accuracy: 0.7490\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 63s 80ms/step - loss: 0.7439 - accuracy: 0.7394 - val_loss: 0.6883 - val_accuracy: 0.7565\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 62s 79ms/step - loss: 0.7096 - accuracy: 0.7509 - val_loss: 0.6209 - val_accuracy: 0.7825\n",
            "current x is:  0.2 and model acc is:  0.7804800271987915\n",
            "sparsity:  [0.2]\n",
            "accuracy list:  [0.7804800271987915]\n",
            "current x is:  0.30000000000000004\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 61s 74ms/step - loss: 0.7694 - accuracy: 0.7308 - val_loss: 0.6868 - val_accuracy: 0.7555\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 0.7330 - accuracy: 0.7447 - val_loss: 0.6548 - val_accuracy: 0.7740\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.7105 - accuracy: 0.7521 - val_loss: 0.6380 - val_accuracy: 0.7770\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 57s 73ms/step - loss: 0.6899 - accuracy: 0.7573 - val_loss: 0.6312 - val_accuracy: 0.7780\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.6744 - accuracy: 0.7638 - val_loss: 0.6450 - val_accuracy: 0.7720\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 63s 78ms/step - loss: 0.7259 - accuracy: 0.7460 - val_loss: 0.7145 - val_accuracy: 0.7425\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.6991 - accuracy: 0.7520 - val_loss: 0.5929 - val_accuracy: 0.7845\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 63s 81ms/step - loss: 0.6674 - accuracy: 0.7650 - val_loss: 0.6896 - val_accuracy: 0.7475\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.6493 - accuracy: 0.7709 - val_loss: 0.5717 - val_accuracy: 0.7965\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 63s 80ms/step - loss: 0.6275 - accuracy: 0.7797 - val_loss: 0.6124 - val_accuracy: 0.7730\n",
            "current x is:  0.30000000000000004 and model acc is:  0.7808200120925903\n",
            "sparsity:  [0.2, 0.30000000000000004]\n",
            "accuracy list:  [0.7804800271987915, 0.7808200120925903]\n",
            "current x is:  0.4\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 59s 72ms/step - loss: 0.6418 - accuracy: 0.7753 - val_loss: 0.5601 - val_accuracy: 0.8110\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 59s 75ms/step - loss: 0.6177 - accuracy: 0.7842 - val_loss: 0.5550 - val_accuracy: 0.7980\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 0.6018 - accuracy: 0.7894 - val_loss: 0.5227 - val_accuracy: 0.8120\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 0.5801 - accuracy: 0.7966 - val_loss: 0.5696 - val_accuracy: 0.7950\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 57s 73ms/step - loss: 0.5705 - accuracy: 0.7996 - val_loss: 0.5341 - val_accuracy: 0.8095\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 64s 81ms/step - loss: 0.6609 - accuracy: 0.7672 - val_loss: 0.6705 - val_accuracy: 0.7530\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.6265 - accuracy: 0.7792 - val_loss: 0.5265 - val_accuracy: 0.8120\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 61s 77ms/step - loss: 0.6066 - accuracy: 0.7853 - val_loss: 0.5265 - val_accuracy: 0.8155\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.5852 - accuracy: 0.7940 - val_loss: 0.4766 - val_accuracy: 0.8425\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 60s 77ms/step - loss: 0.5720 - accuracy: 0.7982 - val_loss: 0.5010 - val_accuracy: 0.8225\n",
            "current x is:  0.4 and model acc is:  0.8275600075721741\n",
            "sparsity:  [0.2, 0.30000000000000004, 0.4]\n",
            "accuracy list:  [0.7804800271987915, 0.7808200120925903, 0.8275600075721741]\n",
            "current x is:  0.5\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 60s 72ms/step - loss: 0.5550 - accuracy: 0.8066 - val_loss: 0.4783 - val_accuracy: 0.8315\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.5229 - accuracy: 0.8187 - val_loss: 0.4779 - val_accuracy: 0.8365\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 0.5099 - accuracy: 0.8226 - val_loss: 0.4533 - val_accuracy: 0.8405\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 57s 73ms/step - loss: 0.4942 - accuracy: 0.8274 - val_loss: 0.4365 - val_accuracy: 0.8555\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 0.4876 - accuracy: 0.8303 - val_loss: 0.4520 - val_accuracy: 0.8405\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 66s 82ms/step - loss: 0.6101 - accuracy: 0.7828 - val_loss: 0.5502 - val_accuracy: 0.8010\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 64s 81ms/step - loss: 0.5775 - accuracy: 0.7953 - val_loss: 0.5068 - val_accuracy: 0.8170\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.5538 - accuracy: 0.8028 - val_loss: 0.5025 - val_accuracy: 0.8220\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.5323 - accuracy: 0.8125 - val_loss: 0.5318 - val_accuracy: 0.8000\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 66s 84ms/step - loss: 0.5311 - accuracy: 0.8120 - val_loss: 0.4626 - val_accuracy: 0.8350\n",
            "current x is:  0.5 and model acc is:  0.8320000171661377\n",
            "sparsity:  [0.2, 0.30000000000000004, 0.4, 0.5]\n",
            "accuracy list:  [0.7804800271987915, 0.7808200120925903, 0.8275600075721741, 0.8320000171661377]\n",
            "current x is:  0.6\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 60s 73ms/step - loss: 0.4984 - accuracy: 0.8260 - val_loss: 0.4171 - val_accuracy: 0.8660\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.4571 - accuracy: 0.8428 - val_loss: 0.3954 - val_accuracy: 0.8685\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 57s 72ms/step - loss: 0.4434 - accuracy: 0.8472 - val_loss: 0.3917 - val_accuracy: 0.8645\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 57s 73ms/step - loss: 0.4324 - accuracy: 0.8512 - val_loss: 0.4127 - val_accuracy: 0.8585\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 0.4201 - accuracy: 0.8555 - val_loss: 0.3729 - val_accuracy: 0.8755\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 64s 80ms/step - loss: 0.5856 - accuracy: 0.7919 - val_loss: 0.4596 - val_accuracy: 0.8305\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.5442 - accuracy: 0.8070 - val_loss: 0.4531 - val_accuracy: 0.8425\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 64s 81ms/step - loss: 0.5187 - accuracy: 0.8171 - val_loss: 0.5627 - val_accuracy: 0.7990\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 65s 83ms/step - loss: 0.5081 - accuracy: 0.8188 - val_loss: 0.4194 - val_accuracy: 0.8530\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 67s 85ms/step - loss: 0.4899 - accuracy: 0.8253 - val_loss: 0.4199 - val_accuracy: 0.8540\n",
            "current x is:  0.6 and model acc is:  0.8523600101470947\n",
            "sparsity:  [0.2, 0.30000000000000004, 0.4, 0.5, 0.6]\n",
            "accuracy list:  [0.7804800271987915, 0.7808200120925903, 0.8275600075721741, 0.8320000171661377, 0.8523600101470947]\n",
            "current x is:  0.7\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 60s 74ms/step - loss: 0.5346 - accuracy: 0.8093 - val_loss: 0.4394 - val_accuracy: 0.8430\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.4611 - accuracy: 0.8371 - val_loss: 0.4036 - val_accuracy: 0.8575\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.4385 - accuracy: 0.8471 - val_loss: 0.3975 - val_accuracy: 0.8635\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.4260 - accuracy: 0.8510 - val_loss: 0.3847 - val_accuracy: 0.8660\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 58s 75ms/step - loss: 0.4134 - accuracy: 0.8570 - val_loss: 0.3802 - val_accuracy: 0.8730\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 64s 80ms/step - loss: 0.6075 - accuracy: 0.7834 - val_loss: 0.5365 - val_accuracy: 0.8075\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 63s 80ms/step - loss: 0.5486 - accuracy: 0.8044 - val_loss: 0.4783 - val_accuracy: 0.8265\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.5209 - accuracy: 0.8143 - val_loss: 0.5256 - val_accuracy: 0.8050\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.5096 - accuracy: 0.8177 - val_loss: 0.4345 - val_accuracy: 0.8385\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.4948 - accuracy: 0.8222 - val_loss: 0.4694 - val_accuracy: 0.8420\n",
            "current x is:  0.7 and model acc is:  0.8290200233459473\n",
            "sparsity:  [0.2, 0.30000000000000004, 0.4, 0.5, 0.6, 0.7]\n",
            "accuracy list:  [0.7804800271987915, 0.7808200120925903, 0.8275600075721741, 0.8320000171661377, 0.8523600101470947, 0.8290200233459473]\n",
            "current x is:  0.7999999999999999\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 60s 72ms/step - loss: 0.7853 - accuracy: 0.7361 - val_loss: 0.6152 - val_accuracy: 0.7890\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.6157 - accuracy: 0.7791 - val_loss: 0.5499 - val_accuracy: 0.7980\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 57s 73ms/step - loss: 0.5745 - accuracy: 0.7924 - val_loss: 0.5444 - val_accuracy: 0.8010\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.5514 - accuracy: 0.8026 - val_loss: 0.4955 - val_accuracy: 0.8225\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 57s 73ms/step - loss: 0.5358 - accuracy: 0.8086 - val_loss: 0.4918 - val_accuracy: 0.8330\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 62s 77ms/step - loss: 0.7208 - accuracy: 0.7445 - val_loss: 0.5983 - val_accuracy: 0.7845\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 62s 80ms/step - loss: 0.6347 - accuracy: 0.7720 - val_loss: 0.5819 - val_accuracy: 0.7805\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.5871 - accuracy: 0.7908 - val_loss: 0.5277 - val_accuracy: 0.8085\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 61s 78ms/step - loss: 0.5464 - accuracy: 0.8036 - val_loss: 0.5498 - val_accuracy: 0.7955\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 63s 80ms/step - loss: 0.5266 - accuracy: 0.8137 - val_loss: 0.4527 - val_accuracy: 0.8450\n",
            "current x is:  0.7999999999999999 and model acc is:  0.8263999819755554\n",
            "sparsity:  [0.2, 0.30000000000000004, 0.4, 0.5, 0.6, 0.7, 0.7999999999999999]\n",
            "accuracy list:  [0.7804800271987915, 0.7808200120925903, 0.8275600075721741, 0.8320000171661377, 0.8523600101470947, 0.8290200233459473, 0.8263999819755554]\n",
            "current x is:  0.8999999999999999\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 60s 73ms/step - loss: 1.1631 - accuracy: 0.6080 - val_loss: 0.9967 - val_accuracy: 0.6430\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 1.0177 - accuracy: 0.6401 - val_loss: 0.9221 - val_accuracy: 0.6780\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 59s 76ms/step - loss: 0.9592 - accuracy: 0.6597 - val_loss: 0.8800 - val_accuracy: 0.6925\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.9235 - accuracy: 0.6722 - val_loss: 0.8608 - val_accuracy: 0.6945\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.8990 - accuracy: 0.6812 - val_loss: 0.8354 - val_accuracy: 0.7120\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 63s 79ms/step - loss: 0.9746 - accuracy: 0.6576 - val_loss: 0.8923 - val_accuracy: 0.6875\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 63s 81ms/step - loss: 0.8448 - accuracy: 0.7041 - val_loss: 0.7456 - val_accuracy: 0.7375\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 63s 80ms/step - loss: 0.7737 - accuracy: 0.7266 - val_loss: 0.7648 - val_accuracy: 0.7220\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 0.7275 - accuracy: 0.7443 - val_loss: 0.6530 - val_accuracy: 0.7565\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 62s 80ms/step - loss: 0.6924 - accuracy: 0.7558 - val_loss: 0.6100 - val_accuracy: 0.7920\n",
            "current x is:  0.8999999999999999 and model acc is:  0.7818199992179871\n",
            "sparsity:  [0.2, 0.30000000000000004, 0.4, 0.5, 0.6, 0.7, 0.7999999999999999, 0.8999999999999999]\n",
            "accuracy list:  [0.7804800271987915, 0.7808200120925903, 0.8275600075721741, 0.8320000171661377, 0.8523600101470947, 0.8290200233459473, 0.8263999819755554, 0.7818199992179871]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_and_pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
        "  f.write(quantized_and_pruned_tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTg8KW_GjfK1",
        "outputId": "b8572571-aa0c-452d-9deb-ed6e3e4503bf"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################\n",
        "##### Pruning + Quantization Result #####\n",
        "#########################################"
      ],
      "metadata": {
        "id": "WFbg8mQ6lk2B"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compression_pq_ratio = [1/x for x in sparsity_pq]\n",
        "compression_pq_ratio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPueWNHHhOLQ",
        "outputId": "eff76ba9-6aba-42e9-e88c-9282d0248a52"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.0,\n",
              " 3.333333333333333,\n",
              " 2.5,\n",
              " 2.0,\n",
              " 1.6666666666666667,\n",
              " 1.4285714285714286,\n",
              " 1.25,\n",
              " 1.1111111111111112]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_pq"
      ],
      "metadata": {
        "id": "s7GVuNyWFzMA",
        "outputId": "693669f4-41d0-4652-ecfe-00ab41b44154",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7804800271987915,\n",
              " 0.7808200120925903,\n",
              " 0.8275600075721741,\n",
              " 0.8320000171661377,\n",
              " 0.8523600101470947,\n",
              " 0.8290200233459473,\n",
              " 0.8263999819755554,\n",
              " 0.7818199992179871]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compression ratio vs accuracy graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "# plt.scatter(compression_rat, acc)\n",
        "ax.plot(compression_pq_ratio, acc_pq, linewidth=2.0)\n",
        "plt.xlabel('Compresion Ratio(Pruned + Quantization)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Compresion Ratio(Pruned + Quantization) VS Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "46peLtbOhON_",
        "outputId": "543c970b-99d5-432b-f1ba-5598c00028e3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy results\n",
        "print('Baseline test accuracy:', baseline_model_accuracy) \n",
        "print('Pruned + Quantization test accuracy:', model_quant_prune_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18J3MhF2hOTF",
        "outputId": "3e6ca3af-a2b2-4f45-8f4f-91cb753071dd"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.599399983882904\n",
            "Pruned + Quantization test accuracy: 0.7818199992179871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare model size\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1dOY6GGhOY_",
        "outputId": "050b861e-14ac-4433-8b84-a4e400476c34"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of gzipped baseline Keras model: 346362.00 bytes\n",
            "Size of gzipped pruned and quantized TFlite model: 24468.00 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix for based model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "test_predictions = model.predict(x_test)\n",
        "confusion = confusion_matrix(y_test, np.argmax(test_predictions,axis=1))\n",
        "confusion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nshNE4_hhOat",
        "outputId": "635946a5-8323-4385-b293-688841fe5673"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 6s 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[694,  34,  55,  22,  16,   3,  12,  16, 101,  47],\n",
              "       [ 20, 785,   4,   8,   6,   3,  17,   7,  44, 106],\n",
              "       [ 78,  15, 465,  84, 123,  72,  65,  55,  26,  17],\n",
              "       [ 22,  19,  81, 407,  88, 161,  85,  61,  40,  36],\n",
              "       [ 36,   7,  82,  80, 579,  28,  73,  88,  16,  11],\n",
              "       [ 16,   9,  70, 187,  64, 497,  39,  94,  10,  14],\n",
              "       [ 14,   8,  34,  67,  62,  40, 724,  17,  15,  19],\n",
              "       [ 17,   7,  40,  62,  78,  63,  12, 677,  10,  34],\n",
              "       [ 83,  60,  13,  22,   6,   4,   5,   4, 772,  31],\n",
              "       [ 35, 136,  11,  21,   7,  12,  11,  22,  53, 692]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix for pruned+quantized model\n",
        "pq_test_predictions = model_quant_prune.predict(x_test)\n",
        "pq_confusion = confusion_matrix(y_test, np.argmax(pq_test_predictions,axis=1))\n",
        "pq_confusion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN-tW_D1lyVZ",
        "outputId": "ea7f3f1b-520f-46e7-db89-825da3c0c2e4"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 7s 21ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[737,  59,  45,  22,  23,   3,   6,  16,  55,  34],\n",
              "       [  9, 861,   6,   9,   4,   1,  13,   7,  17,  73],\n",
              "       [ 62,  16, 589,  70,  81,  37,  48,  64,  13,  20],\n",
              "       [ 27,  22,  87, 489,  85,  96,  56,  69,  25,  44],\n",
              "       [ 28,  11,  90,  78, 591,  24,  43, 115,  15,   5],\n",
              "       [ 16,  10,  77, 250,  49, 438,  30, 100,  13,  17],\n",
              "       [  8,  17,  53,  79,  54,  20, 721,  20,   8,  20],\n",
              "       [ 14,  12,  46,  39,  54,  32,   7, 764,   5,  27],\n",
              "       [ 82,  70,  16,  12,   3,   0,   4,  10, 775,  28],\n",
              "       [ 29, 163,  12,  18,  13,   4,   6,  17,  25, 713]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ib1aHwYmEV7"
      },
      "execution_count": 78,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}